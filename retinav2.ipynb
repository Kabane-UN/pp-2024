{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import os \n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "import albumentations as A \n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pycocotools\n",
    "from random import shuffle\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "from torchmetrics.utilities.imports import _TORCHVISION_GREATER_EQUAL_0_8\n",
    "with_checkpoint = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    \n",
    "    model = tv.models.detection.retinanet_resnet50_fpn_v2(num_classes=num_classes, weights_backbone=tv.models.ResNet50_Weights.DEFAULT, trainable_backbone_layers=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(num_classes=2)\n",
    "checkpoint_epoch = 1\n",
    "if with_checkpoint:\n",
    "    checkpoint = torch.load('retina2.pth', map_location=device)\n",
    "    checkpoint_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 138.877MB\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Blur(\n",
    "            blur_limit=3,\n",
    "            p=0.1\n",
    "        ),\n",
    "        A.MotionBlur(\n",
    "            blur_limit=3,\n",
    "            p=0.1\n",
    "        ),\n",
    "        A.MedianBlur(\n",
    "            blur_limit=3,\n",
    "            p=0.1,\n",
    "        ),\n",
    "        A.ToGray(\n",
    "            p=0.3,\n",
    "        ),\n",
    "        A.RandomBrightnessContrast(\n",
    "            p=0.3,\n",
    "        ),\n",
    "        A.ColorJitter(\n",
    "            p=0.3,\n",
    "        ),\n",
    "        A.RandomGamma(\n",
    "            p=0.3,\n",
    "        ),\n",
    "        ToTensorV2(p=1.0)], \n",
    "        bbox_params={\n",
    "            'format': 'pascal_voc',\n",
    "            'label_fields': ['labels']\n",
    "        }\n",
    "    )\n",
    "def get_test_transforms():\n",
    "    return A.Compose([ToTensorV2(p=1)], bbox_params={\n",
    "            'format': 'pascal_voc',\n",
    "            'label_fields': ['labels']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dir, dir_list, meta, size, transforms=None):\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.dir = dir\n",
    "        self.width, self.height = size\n",
    "        self.dir_list = dir_list\n",
    "        self.meta = meta\n",
    "    def __len__(self):\n",
    "        return len(self.dir_list)\n",
    "    def __getitem__(self, index):\n",
    "        img_file = self.dir_list[index]\n",
    "        img = cv2.imread(os.path.join(self.dir, img_file), cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_width = img.shape[1]\n",
    "        img_height = img.shape[0]\n",
    "        img = img.astype(np.float32)/255.\n",
    "        img = cv2.resize(img, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
    "        t_img = img\n",
    "        # t_img = img.transpose((2, 0, 1))\n",
    "        # t_img = torch.from_numpy(img)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        with open(os.path.join(self.meta, os.path.splitext(img_file)[0]+'.txt'), 'r') as f:\n",
    "            meta_lines = f.readlines()\n",
    "            for meta_line in meta_lines:\n",
    "                face = meta_line.split(\" \")[2:]\n",
    "                labels.append(1)\n",
    "                xmin = float(face[0]) / img_width * self.width\n",
    "                ymin = float(face[1]) / img_height * self.height\n",
    "                xmax = float(face[2]) / img_width * self.width\n",
    "                ymax = float(face[3]) / img_height * self.height\n",
    "                xmax = min(xmax, self.width)\n",
    "                ymax = min(ymax, self.height)\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=img, bboxes=target['boxes'], labels=target['labels'])\n",
    "            t_img = sample['image']\n",
    "            target['boxes'] = torch.Tensor(sample['bboxes'])\n",
    "            target['labels'] = torch.Tensor(sample['labels']).int()\n",
    "        if np.isnan((target['boxes']).numpy()).any() or target['boxes'].shape == torch.Size([0]):\n",
    "            target['boxes'] = torch.zeros((0, 4), dtype=torch.int64)\n",
    "        return t_img, target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_dir,val_dir, meta, size, train_transforms=None, test_transforms=None):\n",
    "    train_list = [file for file in os.listdir(train_dir) \n",
    "                if os.path.splitext(file)[1] in ['.jpg', '.png']]\n",
    "    val_list = [file for file in os.listdir(val_dir) \n",
    "                if os.path.splitext(file)[1] in ['.jpg', '.png']]\n",
    "    return FacesDataset(train_dir, train_list, meta, size, train_transforms), FacesDataset(val_dir, val_list, meta, size, test_transforms)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13386\n",
      "3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrey/work/jupiter/venv/lib/python3.10/site-packages/albumentations/core/composition.py:156: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = create_datasets('faces2/images/train', 'faces2/images/val', 'faces2/labels2', (380, 380), get_train_transforms(), get_test_transforms())\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=1, drop_last=False, collate_fn=collate_fn\n",
    ")\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=1, drop_last=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "if with_checkpoint:\n",
    "    optimizer.load_state_dict(checkpoint['optimazer_state_dict'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average:\n",
    "    def __init__(self):\n",
    "        self.current_total = .0\n",
    "        self.iterations = .0\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1. * self.current_total / self.iterations\n",
    "    def reset(self):\n",
    "        self.current_total = 0.\n",
    "        self.iterations = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(data_loader, model):\n",
    "    global train_loss_hist\n",
    "    model.train()\n",
    "    prog_bar = tqdm(data_loader, total=len(data_loader))\n",
    "    for i, data in enumerate(prog_bar):\n",
    "        optimizer.zero_grad()\n",
    "        img, target = data \n",
    "        target = [{k: v.to(device) for k, v in t.items()} for t in target]\n",
    "        img = list(i.to(device) for i in img)\n",
    "        loss_dict = model(img, target)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        train_loss_hist.send(loss_value)\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        prog_bar.set_description(f'loss: {loss_value:.4f}')\n",
    "    return loss_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_data_loader, model):\n",
    "    model.eval()\n",
    "    targets, preds = [], []\n",
    "    prog_bar = tqdm(valid_data_loader, total=len(valid_data_loader))\n",
    "    for i, data in enumerate(prog_bar):\n",
    "        img, target = data \n",
    "        target = [{k: v.to(device) for k, v in t.items()} for t in target]\n",
    "        img = list(i.to(device) for i in img)\n",
    "        with torch.no_grad():\n",
    "            out = model(img, target)\n",
    "        for j in range(len(img)):\n",
    "            true_dict = {}\n",
    "            pred_dict = {}\n",
    "            true_dict[\"boxes\"] = target[j][\"boxes\"].detach().cpu()\n",
    "            true_dict[\"labels\"] = target[j][\"labels\"].detach().cpu()\n",
    "            pred_dict['labels'] = out[j]['labels'].detach().cpu()\n",
    "            pred_dict['scores'] = out[j]['scores'].detach().cpu()\n",
    "            pred_dict['boxes'] = out[j]['boxes'].detach().cpu()\n",
    "            preds.append(pred_dict)\n",
    "            targets.append(true_dict)\n",
    "    metric = MeanAveragePrecision()\n",
    "    metric.update(preds, targets)\n",
    "    metric_summary = metric.compute()\n",
    "    return metric_summary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    def __init__(\n",
    "        self, best_valid_map=float(0)\n",
    "    ):\n",
    "        self.best_valid_map = best_valid_map\n",
    "        \n",
    "    def __call__(\n",
    "        self, \n",
    "        model, \n",
    "        current_valid_map, \n",
    "        epoch\n",
    "    ):\n",
    "        if current_valid_map > self.best_valid_map:\n",
    "            self.best_valid_map = current_valid_map\n",
    "            print(f\"\\nBEST VALIDATION mAP: {self.best_valid_map}\")\n",
    "            print(f\"\\nSAVING BEST MODEL FOR EPOCH: {epoch+1}\\n\")\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                }, \"best_retina2_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss_plot(\n",
    "    train_loss_list, \n",
    "    x_label='iterations',\n",
    "    y_label='train loss',\n",
    "    save_name='train_retina2_loss'\n",
    "):\n",
    "    figure_1 = plt.figure(figsize=(10, 7), num=1, clear=True)\n",
    "    train_ax = figure_1.add_subplot()\n",
    "    train_ax.plot(train_loss_list, color='tab:blue')\n",
    "    train_ax.set_xlabel(x_label)\n",
    "    train_ax.set_ylabel(y_label)\n",
    "    figure_1.savefig(f\"{save_name}.png\")\n",
    "    print('SAVING PLOTS COMPLETE...')\n",
    "\n",
    "def save_mAP(map_05, map):\n",
    "    figure = plt.figure(figsize=(10, 7), num=1, clear=True)\n",
    "    ax = figure.add_subplot()\n",
    "    ax.plot(\n",
    "        map_05, color='tab:orange', linestyle='-', \n",
    "        label='mAP@0.5'\n",
    "    )\n",
    "    ax.plot(\n",
    "        map, color='tab:red', linestyle='-', \n",
    "        label='mAP@0.5:0.95'\n",
    "    )\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('mAP')\n",
    "    ax.legend()\n",
    "    figure.savefig(f\"retina2_map.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1780: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:40<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:56<00:00,  5.64it/s]\n",
      "/home/andrey/work/jupiter/venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Encountered more than 100 detections in a single image. This means that certain detections with the lowest scores will be ignored, that may have an undesirable impact on performance. Please consider adjusting the `max_detection_threshold` to suit your use case. To disable this warning, set attribute class `warn_on_many_detections=False`, after initializing the metric.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 train loss: 0.289\n",
      "Epoch 23 mAP@0.50:0.95: 0.4941801130771637\n",
      "Epoch 23 mAP@0.50: 0.8004164695739746\n",
      "\n",
      "BEST VALIDATION mAP: 0.4941801130771637\n",
      "\n",
      "SAVING BEST MODEL FOR EPOCH: 23\n",
      "\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.001]\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1501: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:43<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:56<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 train loss: 0.286\n",
      "Epoch 24 mAP@0.50:0.95: 0.49880310893058777\n",
      "Epoch 24 mAP@0.50: 0.8110334277153015\n",
      "\n",
      "BEST VALIDATION mAP: 0.49880310893058777\n",
      "\n",
      "SAVING BEST MODEL FOR EPOCH: 24\n",
      "\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.001]\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1654: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:40<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:54<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 train loss: 0.290\n",
      "Epoch 25 mAP@0.50:0.95: 0.48541197180747986\n",
      "Epoch 25 mAP@0.50: 0.7993677854537964\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.001]\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1344: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:44<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:54<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 train loss: 0.285\n",
      "Epoch 26 mAP@0.50:0.95: 0.48563352227211\n",
      "Epoch 26 mAP@0.50: 0.7919703722000122\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.001]\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0850: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:42<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:57<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 train loss: 0.283\n",
      "Epoch 27 mAP@0.50:0.95: 0.4874163866043091\n",
      "Epoch 27 mAP@0.50: 0.7960348725318909\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.001]\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1147: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:47<00:00,  2.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:50<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 train loss: 0.283\n",
      "Epoch 28 mAP@0.50:0.95: 0.48864275217056274\n",
      "Epoch 28 mAP@0.50: 0.7941462397575378\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.0001]\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0922: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:50<00:00,  2.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:55<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 train loss: 0.227\n",
      "Epoch 29 mAP@0.50:0.95: 0.529974102973938\n",
      "Epoch 29 mAP@0.50: 0.8333792090415955\n",
      "\n",
      "BEST VALIDATION mAP: 0.529974102973938\n",
      "\n",
      "SAVING BEST MODEL FOR EPOCH: 29\n",
      "\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.0001]\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1741: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:41<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:47<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 train loss: 0.209\n",
      "Epoch 30 mAP@0.50:0.95: 0.5292400121688843\n",
      "Epoch 30 mAP@0.50: 0.8312427997589111\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.0001]\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1678: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:37<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:47<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 train loss: 0.200\n",
      "Epoch 31 mAP@0.50:0.95: 0.5305012464523315\n",
      "Epoch 31 mAP@0.50: 0.8327696919441223\n",
      "\n",
      "BEST VALIDATION mAP: 0.5305012464523315\n",
      "\n",
      "SAVING BEST MODEL FOR EPOCH: 31\n",
      "\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.0001]\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1039: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:40<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:50<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 train loss: 0.193\n",
      "Epoch 32 mAP@0.50:0.95: 0.5289576053619385\n",
      "Epoch 32 mAP@0.50: 0.8331999778747559\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.0001]\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.3876: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:34<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:47<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 train loss: 0.187\n",
      "Epoch 33 mAP@0.50:0.95: 0.5293073058128357\n",
      "Epoch 33 mAP@0.50: 0.8338761329650879\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.0001]\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1685: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:42<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:50<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 train loss: 0.182\n",
      "Epoch 34 mAP@0.50:0.95: 0.5301554799079895\n",
      "Epoch 34 mAP@0.50: 0.8349409699440002\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [0.0001]\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1525: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:41<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:50<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 train loss: 0.178\n",
      "Epoch 35 mAP@0.50:0.95: 0.5294625759124756\n",
      "Epoch 35 mAP@0.50: 0.8336709141731262\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1e-05]\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4116: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:50<00:00,  2.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:49<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 train loss: 0.170\n",
      "Epoch 36 mAP@0.50:0.95: 0.5298667550086975\n",
      "Epoch 36 mAP@0.50: 0.8351181745529175\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1e-05]\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0870: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:51<00:00,  2.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:51<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 train loss: 0.168\n",
      "Epoch 37 mAP@0.50:0.95: 0.5307399034500122\n",
      "Epoch 37 mAP@0.50: 0.8344210386276245\n",
      "\n",
      "BEST VALIDATION mAP: 0.5307399034500122\n",
      "\n",
      "SAVING BEST MODEL FOR EPOCH: 37\n",
      "\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1e-05]\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.2216: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:52<00:00,  2.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:49<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 train loss: 0.167\n",
      "Epoch 38 mAP@0.50:0.95: 0.5297397375106812\n",
      "Epoch 38 mAP@0.50: 0.8343560099601746\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1e-05]\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1907: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:43<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:48<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 train loss: 0.166\n",
      "Epoch 39 mAP@0.50:0.95: 0.5282989740371704\n",
      "Epoch 39 mAP@0.50: 0.8306371569633484\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1e-05]\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0855: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:48<00:00,  2.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:50<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 train loss: 0.166\n",
      "Epoch 40 mAP@0.50:0.95: 0.5297796130180359\n",
      "Epoch 40 mAP@0.50: 0.8335580229759216\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1e-05]\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.5369: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:43<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:47<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 train loss: 0.164\n",
      "Epoch 41 mAP@0.50:0.95: 0.5290052890777588\n",
      "Epoch 41 mAP@0.50: 0.8345298171043396\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1.0000000000000002e-06]\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0555: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:45<00:00,  2.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:48<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 train loss: 0.164\n",
      "Epoch 42 mAP@0.50:0.95: 0.5291451215744019\n",
      "Epoch 42 mAP@0.50: 0.8321715593338013\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1.0000000000000002e-06]\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0547: 100%|████████████████████████████████████████████████████████████████| 6693/6693 [52:43<00:00,  2.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1674/1674 [04:48<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 train loss: 0.164\n",
      "Epoch 43 mAP@0.50:0.95: 0.5288277268409729\n",
      "Epoch 43 mAP@0.50: 0.8325561881065369\n",
      "SAVING PLOTS COMPLETE...\n",
      "Lr: [1.0000000000000002e-06]\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.1425:  73%|██████████████████████████████████████████████▉                 | 4907/6693 [38:38<14:04,  2.11it/s]"
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "train_loss_hist = Average()\n",
    "train_loss_list = []\n",
    "map_list = []\n",
    "map_50_list = []\n",
    "save_best_model = SaveBestModel()\n",
    "for epoch in range(checkpoint_epoch-1, epoch_num+checkpoint_epoch-1):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train_loss_hist.reset()\n",
    "    train_loss = train_one_epoch(train_data_loader, model)\n",
    "    metric_summary = validate(test_data_loader, model)\n",
    "    print(f'Epoch {epoch+1} train loss: {train_loss_hist.value:.3f}')\n",
    "    print(f'Epoch {epoch+1} mAP@0.50:0.95: {metric_summary[\"map\"]}')\n",
    "    print(f'Epoch {epoch+1} mAP@0.50: {metric_summary[\"map_50\"]}')\n",
    "    train_loss_list.append(train_loss)\n",
    "    map_50_list.append(metric_summary['map_50'])\n",
    "    map_list.append(metric_summary['map'])\n",
    "    save_best_model(model, float(metric_summary['map']), epoch)\n",
    "    save_loss_plot(train_loss_list)\n",
    "    save_mAP(map_50_list, map_list)\n",
    "    scheduler.step(float(metric_summary['map']))\n",
    "    print(f'Lr: {scheduler.get_last_lr()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimazer_state_dict': optimizer.state_dict()},'retina2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
